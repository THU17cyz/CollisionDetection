# 实验报告

2017013599 软件71 从业臻



### 算法说明

算法设计基本参考了：

- https://developer.nvidia.com/gpugems/gpugems3/part-v-physics-simulation/chapter-32-broad-phase-collision-detection-cuda
- https://developer.download.nvidia.com/assets/cuda/files/particles.pdf

碰撞检测可以分为broad-phase和narrow-phase。broad-phase的作用是消耗较少的时间来排除一些显然的不可能碰撞的物体对。

broad-phase的思路就是将空间划分为小块，对于特殊设计的块来说，位于一个块中的物体，有可能与其发生碰撞的物体一定在某些块中。对于球体来说，narrow-phase可以就是遍历所有球体，将其与所有“有可能”发生碰撞的球体一一计算球心间距离，如果小于两球半径之和则发生碰撞。这里不讨论发生碰撞后的处理方法，主要讨论broad-phase的思路。

首先，如果省去broad-phase，那么复杂度显然是$O(n^2)$；如果我们将空间均匀划分成块，看作是一个三维数组，并且假设一个块内最多容纳常数个物体，那么每个物体只需要与其他最多$C$个物体比较，和$n$无关！

对于本次大作业的任务，完全不需要使用复杂八叉树结构，只需要将空间均匀划分。设定一个块的大小刚好完整的容纳一个最大的球体（块的边长等于最大的球体直径），那么两球若要相撞，其必然在同一个或者相邻的块中（包括斜对角相邻）。在合适的碰撞更新公式下，基本可以认为不会出现很多球体重叠在同一位置的情况。

然而，怎么找到这至多$C$个物体才决定了复杂度的大小。若将空间看成一个个块，可以给每个物体根据其所处块的位置计算一个哈希值，再根据哈希值排序，以排序后的索引为依据寻找处于同一块（或者近邻块）的物体。最简单的哈希函数就是$z\times HASH\_BLOCK^2+y\times HASH\_BLOCK + x$，其中$x,y,z$是所处块分别在三个维度上的序数，$HASH\_BLOCK$是一个预设的$2$的指数。实际实现中，令$HASH\_BLOCK=64$比较合适，因为$64^3>2\times 20^6$，足以为每个块赋予一个唯一的哈希值，并且内存开销也可以接受。在此思路下，将算法拆解为如下步骤：

- 为每个物体计算哈希值（复杂度$O(n)$）
- 根据哈希值排序（由哈希函数特点，使用基数排序，复杂度$O(nd)$，$d$是哈希值最大位数）
- 排序后，哈希值从小到大排列，由一段段连续的相等值构成，我们需要找到这些“相等值”的开始处和结束处，亦即一个块的开始处和结束处（复杂度$O(n)$）
- 有了上一步的信息，就可以遍历所有物体，对每个物体遍历其所处块+相邻块的物体，检测是否发生碰撞，如有则按照公式计算更新（复杂度$O(n)$）

综上这个算法实际的复杂度大约是：$O(n)$，因为哈希函数的设计，避免了$O(nlogn)$，不过常数项应该非常大。



### 实验结果

为了保证碰撞比较密集，该实验下设定所有碰撞的恢复系数都是1（弹性碰撞），随机的初始速度足够大、且初始位置足够紧密，保证一开始就会发生碰撞。

单次实验测试的是`update`1000次的总时间，以下结果均取三次实验平均值，均是Release x64模式。

首先，为了检验算法复杂度，列出CPU上串行实现该算法的表现：

| 球体数量         | 10     | 30     | 100    | 300    | 1000   | 3000   | 10000   | 30000   |
| ---------------- | ------ | ------ | ------ | ------ | ------ | ------ | ------- | ------- |
| 1000次update耗时 | 0.0321 | 0.0422 | 0.0848 | 0.2429 | 1.2182 | 5.6606 | 14.8823 | 57.2691 |

画出取对数后的图（横轴是球数除以10再取对数），整体看比较接近于线性的复杂度。

![cpufast](images\cpufast.png)

然后是GPU上并行实现该算法的表现：

| 球体数量         | 10     | 30     | 100    | 300    | 1000   | 3000   | 10000  | 30000  |
| ---------------- | ------ | ------ | ------ | ------ | ------ | ------ | ------ | ------ |
| 1000次update耗时 | 0.1872 | 0.1965 | 0.2012 | 0.2201 | 0.2500 | 0.3729 | 0.4995 | 1.0083 |

画出取对数后的图（横轴是球数除以10再取对数），可以看出在大约是两段折线，前一段是球数小于1000，后一段是大于1000，这应该和我电脑CUDA设备（GTX 1050）本身的性质和我设置的`num_threads=256`有一定的关系。前一段线程数较小，增加线程几乎不增加时间开销；但线程数增多后，线程的管理也就更加复杂。

![gpufast](images\gpufast.png)

把两张图放在一起：

![fast](images\fast.png)

很明显，GPU上并行化的程序复杂度的常数项比CPU上串行的程序的要小的多。

最后，也列出了暴力算法（$O(n^2)$）的表现：

| 球体数量         | 10     | 30     | 100    | 300    | 1000    | 3000     | 10000 | 30000 |
| ---------------- | ------ | ------ | ------ | ------ | ------- | -------- | ----- | ----- |
| 1000次update耗时 | 0.0024 | 0.0196 | 0.2275 | 1.9305 | 21.2365 | 194.4840 | /     | /     |

画出取对数后的曲线（横轴是球数平方除以100再取对数），验证了复杂度。

![brutal](images\brutal.png)



